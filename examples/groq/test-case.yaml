name: "Llama 3 via Groq"
description: "Test Llama 3.1 70B via Groq's free API"

adapter: http
endpoint: https://api.groq.com/openai/v1/chat/completions

input:
  query: "What is the capital of France?"

expected:
  output:
    contains:
      - "Paris"

thresholds:
  min_score: 70
  max_latency: 5000
